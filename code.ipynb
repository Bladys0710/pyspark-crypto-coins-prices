{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset API key!"
      ],
      "metadata": {
        "id": "ZdE-BjiU7iP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Brg9SITY4Ra3",
        "outputId": "6c9062c0-2071-4a0e-a7eb-8bcacac9f8d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d24ec5f-4679-4d61-8eae-367a3e2e6461\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d24ec5f-4679-4d61-8eae-367a3e2e6461\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following 2 code boxes are used to connect the dataset API and load the data to colab"
      ],
      "metadata": {
        "id": "D9UvZhP06w0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "\n",
        "# To protect API key\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Swpo_UPy4Q0W"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Initialize the Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Download the file\n",
        "api.dataset_download_files('olegshpagin/crypto-coins-prices-ohlcv', path='/content/data/Bitcoin +233 Crypto Coins Prices/', unzip=True)"
      ],
      "metadata": {
        "id": "OKQ9VnnL1DVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8d2721-d062-4150-ccd4-dae9b15b444a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/olegshpagin/crypto-coins-prices-ohlcv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gmnu-Qiq2WcZ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType, DoubleType\n",
        "from pyspark.sql.functions import col, input_file_name, split, regexp_replace, when"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Crypto Coins Prices').getOrCreate()"
      ],
      "metadata": {
        "id": "jcUKva1tAuix"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema\n",
        "schema = StructType([\n",
        "    StructField(\"pair\", StringType(), True),  # This will be populated later\n",
        "    StructField(\"datetime\", TimestampType(), True),\n",
        "    StructField(\"open\", DoubleType(), True),\n",
        "    StructField(\"high\", DoubleType(), True),\n",
        "    StructField(\"low\", DoubleType(), True),\n",
        "    StructField(\"close\", DoubleType(), True),\n",
        "    StructField(\"volume\", DoubleType(), True),\n",
        "])"
      ],
      "metadata": {
        "id": "5GJwHG1LLVHP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your schema (replace with your actual schema)\n",
        "schema = \"datetime STRING, open FLOAT, high FLOAT, low FLOAT, close FLOAT, volume FLOAT\"\n",
        "# Read the CSV files with the defined schema\n",
        "df = spark.read.csv('/content/data/Bitcoin +233 Crypto Coins Prices/M15/*.csv', header=True, schema=schema)\n",
        "\n",
        "# Add the file name column\n",
        "df = df.withColumn(\"file_name\", input_file_name())\n",
        "\n",
        "# Extract the actual filename without the path\n",
        "df = df.withColumn(\"actual_filename\", regexp_replace(col(\"file_name\"), r\"^.*\\/(.*)$\", \"$1\"))\n",
        "\n",
        "# Extract the part before the first underscore\n",
        "df = df.withColumn(\"pair\", split(col(\"actual_filename\"), \"_\").getItem(0))\n",
        "\n",
        "# Select only the original datetime and the before_underscore columns\n",
        "result_df = df.select(\"pair\", \"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\")\n",
        "\n",
        "# Show the final DataFrame with only the desired columns\n",
        "result_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO8bO8K7WYZ2",
        "outputId": "bb6aaeec-cc56-49f9-aca3-80761c7e5570"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "|pair  |datetime           |open    |high    |low     |close   |volume |\n",
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "|ETHBTC|2017-07-14 04:00:00|0.08    |0.0864  |0.08    |0.0864  |8.752  |\n",
            "|ETHBTC|2017-07-14 04:15:00|0.085289|0.086   |0.085128|0.085811|61.042 |\n",
            "|ETHBTC|2017-07-14 04:30:00|0.085811|0.08638 |0.085811|0.086314|53.769 |\n",
            "|ETHBTC|2017-07-14 04:45:00|0.086314|0.08638 |0.086309|0.086347|42.818 |\n",
            "|ETHBTC|2017-07-14 05:00:00|0.085874|0.086205|0.084608|0.08468 |16.52  |\n",
            "|ETHBTC|2017-07-14 05:15:00|0.084581|0.086196|0.084581|0.08585 |22.144 |\n",
            "|ETHBTC|2017-07-14 05:30:00|0.08585 |0.086   |0.085367|0.085669|42.024 |\n",
            "|ETHBTC|2017-07-14 05:45:00|0.085669|0.085957|0.085341|0.085399|33.304 |\n",
            "|ETHBTC|2017-07-14 06:00:00|0.085399|0.087001|0.085398|0.086973|162.135|\n",
            "|ETHBTC|2017-07-14 06:15:00|0.087097|0.087097|0.086883|0.086883|35.316 |\n",
            "|ETHBTC|2017-07-14 06:30:00|0.08678 |0.087117|0.08678 |0.087117|11.306 |\n",
            "|ETHBTC|2017-07-14 06:45:00|0.087253|0.087379|0.0872  |0.0872  |6.25   |\n",
            "|ETHBTC|2017-07-14 07:00:00|0.087005|0.087578|0.087005|0.087578|132.819|\n",
            "|ETHBTC|2017-07-14 07:15:00|0.087312|0.087578|0.087   |0.087578|12.748 |\n",
            "|ETHBTC|2017-07-14 07:30:00|0.088447|0.088669|0.088447|0.08849 |5.074  |\n",
            "|ETHBTC|2017-07-14 07:45:00|0.088591|0.088591|0.088591|0.088591|0.129  |\n",
            "|ETHBTC|2017-07-14 08:00:00|0.088591|0.088591|0.088591|0.088591|0.0    |\n",
            "|ETHBTC|2017-07-14 08:15:00|0.086252|0.086564|0.086252|0.086564|9.802  |\n",
            "|ETHBTC|2017-07-14 08:30:00|0.088564|0.088695|0.08852 |0.088633|55.868 |\n",
            "|ETHBTC|2017-07-14 08:45:00|0.088882|0.088888|0.088669|0.088888|14.671 |\n",
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD0OqipGaijD",
        "outputId": "bad35d96-8b20-4ae2-83c2-1632489482a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25942097"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HZ3bogPa4Jd",
        "outputId": "a0e6f22a-aeeb-4682-8fe9-e4898808505e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------------+-----------------+-----------------+------------------+------------------+-------------------+--------------+--------+\n",
            "|summary|        pair|           datetime|             open|             high|               low|             close|             volume|quote_currency|    coin|\n",
            "+-------+------------+-------------------+-----------------+-----------------+------------------+------------------+-------------------+--------------+--------+\n",
            "|  count|    25942097|           25942097|         25942097|         25942097|          25942097|          25942097|           25942097|      25942097|25942097|\n",
            "|   mean|        NULL|               NULL|315.3085654019528|316.3616548518669|314.22169202798875|315.30973962842415| 2612941.5000165906|          NULL|    NULL|\n",
            "| stddev|        NULL|               NULL|3018.146470177234|3028.201832675217|3007.7704022336616|3018.1641784770873|6.717937442660275E7|          NULL|    NULL|\n",
            "|    min|1000SATSUSDT|2017-07-14 04:00:00|          6.95E-5|          6.95E-5|           6.55E-5|           6.63E-5|                0.0|           BTC|1000SATS|\n",
            "|    max|     ZRXUSDT|2024-03-14 19:15:00|          90746.9|          95000.0|           88000.0|          90901.02|      1.24054217E11|          USDT|     ZRX|\n",
            "+-------+------------+-------------------+-----------------+-----------------+------------------+------------------+-------------------+--------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The folloing code is used to identify the quote currency present on the dataset"
      ],
      "metadata": {
        "id": "64BE_eQeB3ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import substring\n",
        "\n",
        "# Extract the last 4 letters of the 'pair' column\n",
        "df_gr = result_df.withColumn('last_four', substring(col('pair'), -4, 4))\n",
        "\n",
        "# Select distinct last 4 letters\n",
        "unique_last_four = df_gr.select('last_four').distinct()\n",
        "\n",
        "# Show the unique last 4 letters\n",
        "unique_last_four.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14V_fvOqB0G7",
        "outputId": "f36c7749-be09-42b0-a4d7-9dfbbe3aec72"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|last_four|\n",
            "+---------+\n",
            "|HBTC     |\n",
            "|USDT     |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the quote currence identify in previous step, generate 2 new columns: coin and quote_currency.\n"
      ],
      "metadata": {
        "id": "ggShd_V5Stf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Add a new column for ending category based on the 'pair' column\n",
        "result_df = result_df.withColumn(\n",
        "    'quote_currency',\n",
        "    when(col('pair').like('%BTC'), 'BTC')\n",
        "    .when(col('pair').like('%USDT'), 'USDT')\n",
        "    .otherwise('Other')  # Optional: handle other cases\n",
        ")\n",
        "\n",
        "# Add a new column 'coin' by removing the ending category from 'pair'\n",
        "result_df = result_df.withColumn(\n",
        "    'coin',\n",
        "    regexp_replace(col('pair'), '(BTC|USDT)$', '')  # Remove the ending category\n",
        ")\n",
        "\n",
        "# Select only the original datetime and the before_underscore columns\n",
        "res_df = result_df.select(\"coin\", \"quote_currency\",\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\")\n",
        "\n",
        "# Show the updated DataFrame\n",
        "res_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "guioWW4Tn6R4",
        "outputId": "e4cacfe5-de8b-4837-b4e7-f554599baf23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------+-------------------+--------+--------+--------+--------+-------+\n",
            "|coin|quote_currency|datetime           |open    |high    |low     |close   |volume |\n",
            "+----+--------------+-------------------+--------+--------+--------+--------+-------+\n",
            "|ETH |BTC           |2017-07-14 04:00:00|0.08    |0.0864  |0.08    |0.0864  |8.752  |\n",
            "|ETH |BTC           |2017-07-14 04:15:00|0.085289|0.086   |0.085128|0.085811|61.042 |\n",
            "|ETH |BTC           |2017-07-14 04:30:00|0.085811|0.08638 |0.085811|0.086314|53.769 |\n",
            "|ETH |BTC           |2017-07-14 04:45:00|0.086314|0.08638 |0.086309|0.086347|42.818 |\n",
            "|ETH |BTC           |2017-07-14 05:00:00|0.085874|0.086205|0.084608|0.08468 |16.52  |\n",
            "|ETH |BTC           |2017-07-14 05:15:00|0.084581|0.086196|0.084581|0.08585 |22.144 |\n",
            "|ETH |BTC           |2017-07-14 05:30:00|0.08585 |0.086   |0.085367|0.085669|42.024 |\n",
            "|ETH |BTC           |2017-07-14 05:45:00|0.085669|0.085957|0.085341|0.085399|33.304 |\n",
            "|ETH |BTC           |2017-07-14 06:00:00|0.085399|0.087001|0.085398|0.086973|162.135|\n",
            "|ETH |BTC           |2017-07-14 06:15:00|0.087097|0.087097|0.086883|0.086883|35.316 |\n",
            "|ETH |BTC           |2017-07-14 06:30:00|0.08678 |0.087117|0.08678 |0.087117|11.306 |\n",
            "|ETH |BTC           |2017-07-14 06:45:00|0.087253|0.087379|0.0872  |0.0872  |6.25   |\n",
            "|ETH |BTC           |2017-07-14 07:00:00|0.087005|0.087578|0.087005|0.087578|132.819|\n",
            "|ETH |BTC           |2017-07-14 07:15:00|0.087312|0.087578|0.087   |0.087578|12.748 |\n",
            "|ETH |BTC           |2017-07-14 07:30:00|0.088447|0.088669|0.088447|0.08849 |5.074  |\n",
            "|ETH |BTC           |2017-07-14 07:45:00|0.088591|0.088591|0.088591|0.088591|0.129  |\n",
            "|ETH |BTC           |2017-07-14 08:00:00|0.088591|0.088591|0.088591|0.088591|0.0    |\n",
            "|ETH |BTC           |2017-07-14 08:15:00|0.086252|0.086564|0.086252|0.086564|9.802  |\n",
            "|ETH |BTC           |2017-07-14 08:30:00|0.088564|0.088695|0.08852 |0.088633|55.868 |\n",
            "|ETH |BTC           |2017-07-14 08:45:00|0.088882|0.088888|0.088669|0.088888|14.671 |\n",
            "+----+--------------+-------------------+--------+--------+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8lqKk3VV9GiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 1: Filter with a Single Condition\n",
        "Goal: Find all records where the volume is greater than 1 million.\n",
        "\n"
      ],
      "metadata": {
        "id": "Hn-2HI2o9SPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter where volume is greater than 1 million\n",
        "result_df.filter(result_df[\"volume\"] > 1000000).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs5YF5rb9S7D",
        "outputId": "ab2542ff-af93-476f-dcc9-ccdded7d5833"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-------+-------+-------+-------+-----------+--------------+----+\n",
            "|   pair|           datetime|   open|   high|    low|  close|     volume|quote_currency|coin|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+--------------+----+\n",
            "|VETUSDT|2018-07-25 04:00:00| 0.0225|0.02489| 0.0203|0.02106|3.7407276E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 04:15:00|0.02152|0.02269|0.02147|0.02226|3.4112624E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 04:30:00|0.02235| 0.0225|0.02165|0.02246|2.8341142E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 04:45:00|0.02236| 0.0224|  0.022|  0.022| 1.129151E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:00:00|  0.022|0.02206| 0.0213|0.02189|1.3751765E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:15:00| 0.0219| 0.0219| 0.0212|0.02139|  6160434.0|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:30:00|0.02139|0.02189|0.02135|0.02177|  7470119.0|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:45:00|0.02178|0.02225|0.02178|0.02218|  8955663.0|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 06:00:00|0.02219|0.02229|0.02159|0.02159|1.2489702E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 06:15:00|0.02159|0.02167| 0.0215|0.02164|  5894843.0|          USDT| VET|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+--------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 2: Filter with a Single Condition on Date"
      ],
      "metadata": {
        "id": "bi1A3VPu9UtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Filter where datetime is after 2022-01-01\n",
        "result_df.filter(col(\"datetime\") > \"2022-01-01\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMupZlTn9X_d",
        "outputId": "e0c1421f-4ca2-4a04-9ba9-e400338e1036"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+--------+--------+---------+--------------+----+\n",
            "|  pair|           datetime|    open|    high|     low|   close|   volume|quote_currency|coin|\n",
            "+------+-------------------+--------+--------+--------+--------+---------+--------------+----+\n",
            "|ETHBTC|2022-01-01 00:00:00|0.079544|0.079757|0.079541|0.079672|1307.2555|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 00:15:00|0.079672|0.079762|0.079667|0.079737| 396.1373|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 00:30:00|0.079736|0.079736|  0.0796|0.079696| 485.6153|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 00:45:00|0.079695|0.079808|0.079682|0.079805| 603.3572|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 01:00:00|0.079805|0.079805| 0.07969|0.079714| 601.3664|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 01:15:00|0.079709|0.079866|0.079705|0.079837|1219.3774|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 01:30:00|0.079837|0.079886|0.079754|0.079834| 663.1523|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 01:45:00|0.079833|0.079841| 0.07957|0.079637| 517.7116|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 02:00:00|0.079628|0.079673|0.079527|0.079538|  478.672|           BTC| ETH|\n",
            "|ETHBTC|2022-01-01 02:15:00|0.079541|0.079677| 0.07954|0.079635| 482.1326|           BTC| ETH|\n",
            "+------+-------------------+--------+--------+--------+--------+---------+--------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 3: Multiple Conditions — AND fucntion"
      ],
      "metadata": {
        "id": "VMF9cT0z9b5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# High price greater than 50000 AND volume > 2,000,000\n",
        "result_df.filter((col(\"high\") > 50000) & (col(\"volume\") > 2000000)).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An1uEhc_9cr3",
        "outputId": "a652ff4e-8c50-4ec8-d208-fadd09678a09"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+----+----+---+-----+------+--------------+----+\n",
            "|pair|datetime|open|high|low|close|volume|quote_currency|coin|\n",
            "+----+--------+----+----+---+-----+------+--------------+----+\n",
            "+----+--------+----+----+---+-----+------+--------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 4: Multiple Conditions — OR"
      ],
      "metadata": {
        "id": "HMtPAcfe9fDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open price OR close price is less than 100\n",
        "result_df.filter((col(\"open\") < 100) | (col(\"close\") < 100)).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CmFI3G59iha",
        "outputId": "358d53c7-41c5-40cb-936d-9652c6545aed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+--------+--------+-------+--------------+----+\n",
            "|  pair|           datetime|    open|    high|     low|   close| volume|quote_currency|coin|\n",
            "+------+-------------------+--------+--------+--------+--------+-------+--------------+----+\n",
            "|ETHBTC|2017-07-14 04:00:00|    0.08|  0.0864|    0.08|  0.0864|  8.752|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 04:15:00|0.085289|   0.086|0.085128|0.085811| 61.042|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 04:30:00|0.085811| 0.08638|0.085811|0.086314| 53.769|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 04:45:00|0.086314| 0.08638|0.086309|0.086347| 42.818|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 05:00:00|0.085874|0.086205|0.084608| 0.08468|  16.52|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 05:15:00|0.084581|0.086196|0.084581| 0.08585| 22.144|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 05:30:00| 0.08585|   0.086|0.085367|0.085669| 42.024|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 05:45:00|0.085669|0.085957|0.085341|0.085399| 33.304|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 06:00:00|0.085399|0.087001|0.085398|0.086973|162.135|           BTC| ETH|\n",
            "|ETHBTC|2017-07-14 06:15:00|0.087097|0.087097|0.086883|0.086883| 35.316|           BTC| ETH|\n",
            "+------+-------------------+--------+--------+--------+--------+-------+--------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Query number 5: Combined AND + OR"
      ],
      "metadata": {
        "id": "vpB1Se0M9nd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open < 100 AND (volume > 1 million OR high > 90000)\n",
        "result_df.filter((col(\"open\") < 100) & ((col(\"volume\") > 1000000) | (col(\"high\") > 90000))).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWMnCYhQ9pfS",
        "outputId": "3b3e1bfc-908b-4a04-87cf-8e2c691e2751"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-------+-------+-------+-------+-----------+--------------+----+\n",
            "|   pair|           datetime|   open|   high|    low|  close|     volume|quote_currency|coin|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+--------------+----+\n",
            "|VETUSDT|2018-07-25 04:00:00| 0.0225|0.02489| 0.0203|0.02106|3.7407276E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 04:15:00|0.02152|0.02269|0.02147|0.02226|3.4112624E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 04:30:00|0.02235| 0.0225|0.02165|0.02246|2.8341142E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 04:45:00|0.02236| 0.0224|  0.022|  0.022| 1.129151E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:00:00|  0.022|0.02206| 0.0213|0.02189|1.3751765E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:15:00| 0.0219| 0.0219| 0.0212|0.02139|  6160434.0|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:30:00|0.02139|0.02189|0.02135|0.02177|  7470119.0|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 05:45:00|0.02178|0.02225|0.02178|0.02218|  8955663.0|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 06:00:00|0.02219|0.02229|0.02159|0.02159|1.2489702E7|          USDT| VET|\n",
            "|VETUSDT|2018-07-25 06:15:00|0.02159|0.02167| 0.0215|0.02164|  5894843.0|          USDT| VET|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+--------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task B\n",
        "creating a new column called price_range, which shows the difference between the high and low prices for each row — a very common metric in financial/crypto data analysis."
      ],
      "metadata": {
        "id": "5xTEBI0E9qcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create a new column called 'price_range' = high - low\n",
        "result_df = result_df.withColumn(\"price_range\", col(\"high\") - col(\"low\"))\n",
        "\n",
        "# Show a few rows to confirm the new column is added correctly\n",
        "result_df.select(\"pair\", \"datetime\", \"high\", \"low\", \"price_range\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaAWq3lD9t6R",
        "outputId": "852f5d72-e858-44fb-9d6c-809202b534e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+------------+\n",
            "|  pair|           datetime|    high|     low| price_range|\n",
            "+------+-------------------+--------+--------+------------+\n",
            "|ETHBTC|2017-07-14 04:00:00|  0.0864|    0.08| 0.006400004|\n",
            "|ETHBTC|2017-07-14 04:15:00|   0.086|0.085128|8.7200105E-4|\n",
            "|ETHBTC|2017-07-14 04:30:00| 0.08638|0.085811|5.6900084E-4|\n",
            "|ETHBTC|2017-07-14 04:45:00| 0.08638|0.086309| 7.099658E-5|\n",
            "|ETHBTC|2017-07-14 05:00:00|0.086205|0.084608|0.0015969947|\n",
            "|ETHBTC|2017-07-14 05:15:00|0.086196|0.084581|0.0016149953|\n",
            "|ETHBTC|2017-07-14 05:30:00|   0.086|0.085367| 6.330013E-4|\n",
            "|ETHBTC|2017-07-14 05:45:00|0.085957|0.085341| 6.159991E-4|\n",
            "|ETHBTC|2017-07-14 06:00:00|0.087001|0.085398|0.0016029999|\n",
            "|ETHBTC|2017-07-14 06:15:00|0.087097|0.086883|2.1399558E-4|\n",
            "+------+-------------------+--------+--------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "withColumn(\"price_range\",) creates a new column.\n",
        "\n",
        "col(\"high\") - col(\"low\") subtracts values row-by-row.\n",
        "\n",
        "This helps visualize how volatile a crypto pair was during that period."
      ],
      "metadata": {
        "id": "wH8OAiU39vf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task C: Perform Aggregate Functions in PySpark\n",
        "We’ll run at least two aggregation queries using:\n",
        "\n",
        "avg() for average close price\n",
        "max() for maximum volume"
      ],
      "metadata": {
        "id": "xsQUnFWT9yvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, max, min, sum"
      ],
      "metadata": {
        "id": "ix_RuDkB91Hj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average close price\n",
        "avg_close = result_df.agg(avg(\"close\").alias(\"avg_close_price\"))\n",
        "avg_close.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOfD25-R93DC",
        "outputId": "2af62951-d01a-48f8-bf83-66c925a32c54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|   avg_close_price|\n",
            "+------------------+\n",
            "|315.30973962842415|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 2 — Mininmum open price of the entire data set means all the pairs"
      ],
      "metadata": {
        "id": "rGSFmtuk97Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.agg(min(\"open\").alias(\"min_open_price\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POxvW7P598Ia",
        "outputId": "aee99327-f2db-42a0-b575-e8c40ea19036"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|min_open_price|\n",
            "+--------------+\n",
            "|       6.95E-5|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task D\n",
        "Group by pair and calculate average close price"
      ],
      "metadata": {
        "id": "wdqDWQR49-YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# Group by trading pair and calculate average close price\n",
        "avg_close_per_pair = result_df.groupBy(\"pair\") \\\n",
        "    .agg(avg(\"close\").alias(\"avg_close_price\"))\n",
        "\n",
        "# Show the result\n",
        "avg_close_per_pair.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-NOxdCK-Cvv",
        "outputId": "00648725-051b-4f52-b51b-0253d719dcc6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|pair    |avg_close_price     |\n",
            "+--------+--------------------+\n",
            "|VETUSDT |0.033351619857801926|\n",
            "|TRXUSDT |0.05289777105559504 |\n",
            "|BTCUSDT |21807.118113527038  |\n",
            "|BNBUSDT |172.21060789427383  |\n",
            "|ADAUSDT |0.48033505673984955 |\n",
            "|ETHUSDT |1251.8066989186987  |\n",
            "|ETHBTC  |0.05157799774743873 |\n",
            "|XLMUSDT |0.16146420606724426 |\n",
            "|LTCUSDT |96.91862814289583   |\n",
            "|IOTAUSDT|0.4964321518321508  |\n",
            "+--------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "explanation\n",
        "groupBy(\"pair\"): groups all rows by the pair value\n",
        "\n",
        ".agg(avg(\"close\")): calculates the average closing price for each group\n",
        "\n",
        ".alias(...): renames the resulting column for clarity\n",
        "\n"
      ],
      "metadata": {
        "id": "qi-y_BUz-ED5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task E: Top 10 Highest Volume Trades Across All Pairs"
      ],
      "metadata": {
        "id": "WqM1od13-IW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame by volume in descending order\n",
        "sorted_volume_df = result_df.orderBy(result_df[\"volume\"].desc())\n",
        "\n",
        "# Show the top 10 highest volume records\n",
        "sorted_volume_df.select(\"pair\", \"datetime\", \"volume\").show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qjE6Yx_-Kaj",
        "outputId": "236076f8-fdcd-44dc-f614-f3d67830a7cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+-------------+\n",
            "|pair        |datetime           |volume       |\n",
            "+------------+-------------------+-------------+\n",
            "|1000SATSUSDT|2023-12-12 12:00:00|1.24054217E11|\n",
            "|1000SATSUSDT|2023-12-12 12:15:00|4.2619228E10 |\n",
            "|1000SATSUSDT|2023-12-12 12:30:00|4.2222641E10 |\n",
            "|1000SATSUSDT|2023-12-14 16:00:00|3.5824419E10 |\n",
            "|1000SATSUSDT|2023-12-18 09:15:00|3.32747162E10|\n",
            "|1000SATSUSDT|2023-12-14 01:00:00|3.27737324E10|\n",
            "|1000SATSUSDT|2023-12-15 07:15:00|3.26273085E10|\n",
            "|1000SATSUSDT|2023-12-15 12:15:00|3.16866376E10|\n",
            "|1000SATSUSDT|2024-01-03 12:00:00|3.03175864E10|\n",
            "|1000SATSUSDT|2024-03-12 01:00:00|2.90051011E10|\n",
            "+------------+-------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "orderBy(...desc()): sorts from highest to lowest\n",
        "\n",
        "This helps find which coins had the most trading activity during a specific time"
      ],
      "metadata": {
        "id": "mX-hTJvk-Ni3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task F: We'll create a Left Join between:\n",
        "\n",
        "Your existing DataFrame result_df\n",
        "A second DataFrame containing the average volume per pair"
      ],
      "metadata": {
        "id": "t7xB2ftf-QH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Create a DataFrame with Average Volume Per Pair\n",
        " from pyspark.sql.functions import avg\n",
        "\n",
        "avg_volume_df = result_df.groupBy(\"pair\") \\\n",
        "    .agg(avg(\"volume\").alias(\"avg_volume\"))"
      ],
      "metadata": {
        "id": "_S_ucIy3-SAt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performimng a Left Join on pair"
      ],
      "metadata": {
        "id": "zJGmDLwd-Vwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df = result_df.join(avg_volume_df, on=\"pair\", how=\"left\")\n",
        "\n",
        "# Show sample result\n",
        "joined_df.select(\"pair\", \"datetime\", \"volume\", \"avg_volume\").show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xffcV0Dp-XjD",
        "outputId": "b04fa11b-a33e-4b2f-b7ba-3d072692580c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+-------+------------------+\n",
            "|pair  |datetime           |volume |avg_volume        |\n",
            "+------+-------------------+-------+------------------+\n",
            "|ETHBTC|2017-07-14 04:00:00|8.752  |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 04:15:00|61.042 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 04:30:00|53.769 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 04:45:00|42.818 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:00:00|16.52  |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:15:00|22.144 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:30:00|42.024 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:45:00|33.304 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 06:00:00|162.135|1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 06:15:00|35.316 |1674.6737597779027|\n",
            "+------+-------------------+-------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "result_df contains individual trades\n",
        "\n",
        "avg_volume_df provides summary per pair\n",
        "The Left Join adds a new column avg_volume to each record, letting you compare individual volume vs average volume"
      ],
      "metadata": {
        "id": "PXoz_iyh-a50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task G Window Functions[link text](https://)\n",
        "Import Required Modules"
      ],
      "metadata": {
        "id": "sXkkMq0U-eLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, dense_rank, lag, lead"
      ],
      "metadata": {
        "id": "Jhv3-Fsb-gQC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define window: partition by pair, order by volume descending\n",
        "window_spec_rank = Window.partitionBy(\"pair\").orderBy(result_df[\"volume\"].desc())\n",
        "\n",
        "# Apply rank\n",
        "ranked_df = result_df.withColumn(\"volume_rank\", rank().over(window_spec_rank))\n",
        "\n",
        "# Show ranked results\n",
        "ranked_df.select(\"pair\", \"datetime\", \"volume\", \"volume_rank\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZJMV9KS-iIH",
        "outputId": "654f2f2a-e170-4152-dd41-11fbdb0206f5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-----------+-----------+\n",
            "|    pair|           datetime|     volume|volume_rank|\n",
            "+--------+-------------------+-----------+-----------+\n",
            "|AGIXUSDT|2023-03-03 01:30:00|2.5388476E7|          1|\n",
            "|AGIXUSDT|2024-02-16 09:30:00| 1.873388E7|          2|\n",
            "|AGIXUSDT|2023-03-14 17:00:00|1.8614436E7|          3|\n",
            "|AGIXUSDT|2023-05-25 16:00:00|1.8072368E7|          4|\n",
            "|AGIXUSDT|2023-03-14 18:45:00|1.7988518E7|          5|\n",
            "|AGIXUSDT|2023-06-22 10:00:00|1.6398441E7|          6|\n",
            "|AGIXUSDT|2023-02-28 04:00:00|  1.61187E7|          7|\n",
            "|AGIXUSDT|2023-03-14 19:15:00| 1.561941E7|          8|\n",
            "|AGIXUSDT|2023-03-22 18:00:00|1.5500232E7|          9|\n",
            "|AGIXUSDT|2024-02-21 22:45:00|1.5429726E7|         10|\n",
            "+--------+-------------------+-----------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 2: Use lag() to compare close price to previous row (per pair)"
      ],
      "metadata": {
        "id": "7UJu1sN0-lpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define window: partition by pair, order by datetime\n",
        "window_spec_lag = Window.partitionBy(\"pair\").orderBy(\"datetime\")\n",
        "\n",
        "# Add lag column (previous row's close)\n",
        "lag_df = result_df.withColumn(\"previous_close\", lag(\"close\", 1).over(window_spec_lag))\n",
        "\n",
        "# Show result with previous close comparison\n",
        "lag_df.select(\"pair\", \"datetime\", \"close\", \"previous_close\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4V9XGV_-nF3",
        "outputId": "b16ec9a4-3251-49b0-9eaa-9b09d0a31d1c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-------+--------------+\n",
            "|    pair|           datetime|  close|previous_close|\n",
            "+--------+-------------------+-------+--------------+\n",
            "|AGIXUSDT|2023-02-17 08:00:00|0.43829|          NULL|\n",
            "|AGIXUSDT|2023-02-17 08:15:00|0.42992|       0.43829|\n",
            "|AGIXUSDT|2023-02-17 08:30:00|0.43236|       0.42992|\n",
            "|AGIXUSDT|2023-02-17 08:45:00|0.43561|       0.43236|\n",
            "|AGIXUSDT|2023-02-17 09:00:00|0.43194|       0.43561|\n",
            "|AGIXUSDT|2023-02-17 09:15:00|0.43121|       0.43194|\n",
            "|AGIXUSDT|2023-02-17 09:30:00|0.43136|       0.43121|\n",
            "|AGIXUSDT|2023-02-17 09:45:00|0.43351|       0.43136|\n",
            "|AGIXUSDT|2023-02-17 10:00:00|0.43262|       0.43351|\n",
            "|AGIXUSDT|2023-02-17 10:15:00| 0.4336|       0.43262|\n",
            "+--------+-------------------+-------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: rank(): assigns volume-based rank within each pair\n",
        "\n",
        "lag(): brings in previous row’s close price for comparison"
      ],
      "metadata": {
        "id": "R2M8DJad-qX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task H: Aggregate Window Functions\n",
        "These combine aggregates (like avg, sum) with windowing, allowing you to calculate running totals, moving averages, and group-based aggregates without collapsing rows (unlike groupBy())."
      ],
      "metadata": {
        "id": "8hBjJkOc-std"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, sum\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "mYGx0LcV-t07"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number  1: Moving Average of Close Price (Per Pair Ordered by Date)"
      ],
      "metadata": {
        "id": "kPUlrxNk-zC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a rolling window: current row and 2 previous rows, ordered by datetime\n",
        "window_spec_avg = Window.partitionBy(\"pair\").orderBy(\"datetime\").rowsBetween(-2, 0)\n",
        "\n",
        "# Add 3-row moving average column\n",
        "moving_avg_df = result_df.withColumn(\"moving_avg_close\", avg(\"close\").over(window_spec_avg))\n",
        "\n",
        "# Show result\n",
        "moving_avg_df.select(\"pair\", \"datetime\", \"close\", \"moving_avg_close\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpUK5T4B-1Gx",
        "outputId": "ee30bf11-fc6b-4dd0-875c-cf25d1f6d2bb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-------+-------------------+\n",
            "|    pair|           datetime|  close|   moving_avg_close|\n",
            "+--------+-------------------+-------+-------------------+\n",
            "|AGIXUSDT|2023-02-17 08:00:00|0.43829|  0.438289999961853|\n",
            "|AGIXUSDT|2023-02-17 08:15:00|0.42992| 0.4341049939393997|\n",
            "|AGIXUSDT|2023-02-17 08:30:00|0.43236| 0.4335233271121979|\n",
            "|AGIXUSDT|2023-02-17 08:45:00|0.43561|0.43262999256451923|\n",
            "|AGIXUSDT|2023-02-17 09:00:00|0.43194| 0.4333033263683319|\n",
            "|AGIXUSDT|2023-02-17 09:15:00|0.43121| 0.4329199989636739|\n",
            "|AGIXUSDT|2023-02-17 09:30:00|0.43136|0.43150333563486737|\n",
            "|AGIXUSDT|2023-02-17 09:45:00|0.43351| 0.4320266743501027|\n",
            "|AGIXUSDT|2023-02-17 10:00:00|0.43262|0.43249666690826416|\n",
            "|AGIXUSDT|2023-02-17 10:15:00| 0.4336| 0.4332433342933655|\n",
            "+--------+-------------------+-------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Query number 2: Running Total of Volume (Cumulative Sum per Pair)"
      ],
      "metadata": {
        "id": "DKlgqzPO-3et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define cumulative window ordered by datetime per pair\n",
        "window_spec_sum = Window.partitionBy(\"pair\").orderBy(\"datetime\").rowsBetween(Window.unboundedPreceding, 0)\n",
        "\n",
        "# Add cumulative volume column\n",
        "running_total_df = result_df.withColumn(\"cumulative_volume\", sum(\"volume\").over(window_spec_sum))\n",
        "\n",
        "# Show result\n",
        "running_total_df.select(\"pair\", \"datetime\", \"volume\", \"cumulative_volume\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsriMjwL-5Db",
        "outputId": "abf6def2-97f4-4b32-882d-aea9d1672e83"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+---------+-----------------+\n",
            "|    pair|           datetime|   volume|cumulative_volume|\n",
            "+--------+-------------------+---------+-----------------+\n",
            "|AGIXUSDT|2023-02-17 08:00:00|3256768.0|        3256768.0|\n",
            "|AGIXUSDT|2023-02-17 08:15:00|1236058.0|        4492826.0|\n",
            "|AGIXUSDT|2023-02-17 08:30:00| 840131.0|        5332957.0|\n",
            "|AGIXUSDT|2023-02-17 08:45:00| 377821.0|        5710778.0|\n",
            "|AGIXUSDT|2023-02-17 09:00:00| 672372.0|        6383150.0|\n",
            "|AGIXUSDT|2023-02-17 09:15:00| 200868.0|        6584018.0|\n",
            "|AGIXUSDT|2023-02-17 09:30:00| 395115.0|        6979133.0|\n",
            "|AGIXUSDT|2023-02-17 09:45:00| 434877.0|        7414010.0|\n",
            "|AGIXUSDT|2023-02-17 10:00:00| 437388.0|        7851398.0|\n",
            "|AGIXUSDT|2023-02-17 10:15:00| 665352.0|        8516750.0|\n",
            "+--------+-------------------+---------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "rowsBetween(-2, 0) = current row and 2 previous → perfect for moving average\n",
        "\n",
        "Window.unboundedPreceding = start from beginning → perfect for running totals\n",
        "The result keeps row granularity, unlike groupBy()"
      ],
      "metadata": {
        "id": "beVYPZpt-70r"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}