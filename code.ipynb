{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following 3 code boxes are used to load the dataset. The first one is used to load the API key!"
      ],
      "metadata": {
        "id": "ZdE-BjiU7iP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Brg9SITY4Ra3",
        "outputId": "08f9d861-4ae7-480a-f478-e958d3017922"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eee45bf1-23dd-470f-99d5-2537a1f8da82\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eee45bf1-23dd-470f-99d5-2537a1f8da82\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "os.rename('kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "\n",
        "# To protect API key\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Swpo_UPy4Q0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "6e93797b-2212-45ac-cc65-e03a7cbcab84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'kaggle.json' -> '/root/.kaggle/kaggle.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e6a71679f41e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/root/.kaggle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kaggle.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/root/.kaggle/kaggle.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# To protect API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kaggle.json' -> '/root/.kaggle/kaggle.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "# Initialize the Kaggle API\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "# Download the file\n",
        "api.dataset_download_files('olegshpagin/crypto-coins-prices-ohlcv', path='/content/data/Bitcoin +233 Crypto Coins Prices/', unzip=True)"
      ],
      "metadata": {
        "id": "OKQ9VnnL1DVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7bb811-7980-4432-b8e3-76377de4d476"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/olegshpagin/crypto-coins-prices-ohlcv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gmnu-Qiq2WcZ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType, DoubleType, StringType\n",
        "from pyspark.sql.functions import col, to_date, input_file_name, split, regexp_replace"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Crypto Coins Prices').getOrCreate()"
      ],
      "metadata": {
        "id": "jcUKva1tAuix"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema\n",
        "schema = StructType([\n",
        "    StructField(\"pair\", StringType(), True),  # This will be populated later\n",
        "    StructField(\"datetime\", TimestampType(), True),\n",
        "    StructField(\"open\", DoubleType(), True),\n",
        "    StructField(\"high\", DoubleType(), True),\n",
        "    StructField(\"low\", DoubleType(), True),\n",
        "    StructField(\"close\", DoubleType(), True),\n",
        "    StructField(\"volume\", DoubleType(), True),\n",
        "])"
      ],
      "metadata": {
        "id": "5GJwHG1LLVHP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your schema (replace with your actual schema)\n",
        "schema = \"datetime STRING, open FLOAT, high FLOAT, low FLOAT, close FLOAT, volume FLOAT\"\n",
        "# Read the CSV files with the defined schema\n",
        "df = spark.read.csv('/content/data/Bitcoin +233 Crypto Coins Prices/M15/*.csv', header=True, schema=schema)\n",
        "\n",
        "# Add the file name column\n",
        "df = df.withColumn(\"file_name\", input_file_name())\n",
        "\n",
        "# Extract the actual filename without the path\n",
        "df = df.withColumn(\"actual_filename\", regexp_replace(col(\"file_name\"), r\"^.*\\/(.*)$\", \"$1\"))\n",
        "\n",
        "# Extract the part before the first underscore\n",
        "df = df.withColumn(\"pair\", split(col(\"actual_filename\"), \"_\").getItem(0))\n",
        "\n",
        "# Select only the original datetime and the before_underscore columns\n",
        "result_df = df.select(\"pair\", \"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\")\n",
        "\n",
        "# Show the final DataFrame with only the desired columns\n",
        "result_df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO8bO8K7WYZ2",
        "outputId": "001bcdef-e4be-48d0-b07b-f2bc02d9d0e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "|pair  |datetime           |open    |high    |low     |close   |volume |\n",
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "|ETHBTC|2017-07-14 04:00:00|0.08    |0.0864  |0.08    |0.0864  |8.752  |\n",
            "|ETHBTC|2017-07-14 04:15:00|0.085289|0.086   |0.085128|0.085811|61.042 |\n",
            "|ETHBTC|2017-07-14 04:30:00|0.085811|0.08638 |0.085811|0.086314|53.769 |\n",
            "|ETHBTC|2017-07-14 04:45:00|0.086314|0.08638 |0.086309|0.086347|42.818 |\n",
            "|ETHBTC|2017-07-14 05:00:00|0.085874|0.086205|0.084608|0.08468 |16.52  |\n",
            "|ETHBTC|2017-07-14 05:15:00|0.084581|0.086196|0.084581|0.08585 |22.144 |\n",
            "|ETHBTC|2017-07-14 05:30:00|0.08585 |0.086   |0.085367|0.085669|42.024 |\n",
            "|ETHBTC|2017-07-14 05:45:00|0.085669|0.085957|0.085341|0.085399|33.304 |\n",
            "|ETHBTC|2017-07-14 06:00:00|0.085399|0.087001|0.085398|0.086973|162.135|\n",
            "|ETHBTC|2017-07-14 06:15:00|0.087097|0.087097|0.086883|0.086883|35.316 |\n",
            "|ETHBTC|2017-07-14 06:30:00|0.08678 |0.087117|0.08678 |0.087117|11.306 |\n",
            "|ETHBTC|2017-07-14 06:45:00|0.087253|0.087379|0.0872  |0.0872  |6.25   |\n",
            "|ETHBTC|2017-07-14 07:00:00|0.087005|0.087578|0.087005|0.087578|132.819|\n",
            "|ETHBTC|2017-07-14 07:15:00|0.087312|0.087578|0.087   |0.087578|12.748 |\n",
            "|ETHBTC|2017-07-14 07:30:00|0.088447|0.088669|0.088447|0.08849 |5.074  |\n",
            "|ETHBTC|2017-07-14 07:45:00|0.088591|0.088591|0.088591|0.088591|0.129  |\n",
            "|ETHBTC|2017-07-14 08:00:00|0.088591|0.088591|0.088591|0.088591|0.0    |\n",
            "|ETHBTC|2017-07-14 08:15:00|0.086252|0.086564|0.086252|0.086564|9.802  |\n",
            "|ETHBTC|2017-07-14 08:30:00|0.088564|0.088695|0.08852 |0.088633|55.868 |\n",
            "|ETHBTC|2017-07-14 08:45:00|0.088882|0.088888|0.088669|0.088888|14.671 |\n",
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD0OqipGaijD",
        "outputId": "728362c2-f921-4108-d4c8-bc128724750c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25942097"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.describe().show()"
      ],
      "metadata": {
        "id": "2HZ3bogPa4Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507e5ff6-42a2-4ca5-f76e-4ebc14c1f96c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------------------+-----------------+-----------------+------------------+------------------+-------------------+\n",
            "|summary|        pair|           datetime|             open|             high|               low|             close|             volume|\n",
            "+-------+------------+-------------------+-----------------+-----------------+------------------+------------------+-------------------+\n",
            "|  count|    25942097|           25942097|         25942097|         25942097|          25942097|          25942097|           25942097|\n",
            "|   mean|        NULL|               NULL|315.3085654019528|316.3616548518669|314.22169202798875|315.30973962842415| 2612941.5000165906|\n",
            "| stddev|        NULL|               NULL|3018.146470177234|3028.201832675217|3007.7704022336616|3018.1641784770873|6.717937442660275E7|\n",
            "|    min|1000SATSUSDT|2017-07-14 04:00:00|          6.95E-5|          6.95E-5|           6.55E-5|           6.63E-5|                0.0|\n",
            "|    max|     ZRXUSDT|2024-03-14 19:15:00|          90746.9|          95000.0|           88000.0|          90901.02|      1.24054217E11|\n",
            "+-------+------------+-------------------+-----------------+-----------------+------------------+------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 1: Filter with a Single Condition\n",
        "Goal: Find all records where the volume is greater than 1 million.\n",
        "\n"
      ],
      "metadata": {
        "id": "ggShd_V5Stf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter where volume is greater than 1 million\n",
        "result_df.filter(result_df[\"volume\"] > 1000000).show(10)"
      ],
      "metadata": {
        "id": "Np0K6kB8S3_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e63bc9d-bc03-4add-9550-3b38881ca35f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-------+-------+-------+-------+-----------+\n",
            "|   pair|           datetime|   open|   high|    low|  close|     volume|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+\n",
            "|VETUSDT|2018-07-25 04:00:00| 0.0225|0.02489| 0.0203|0.02106|3.7407276E7|\n",
            "|VETUSDT|2018-07-25 04:15:00|0.02152|0.02269|0.02147|0.02226|3.4112624E7|\n",
            "|VETUSDT|2018-07-25 04:30:00|0.02235| 0.0225|0.02165|0.02246|2.8341142E7|\n",
            "|VETUSDT|2018-07-25 04:45:00|0.02236| 0.0224|  0.022|  0.022| 1.129151E7|\n",
            "|VETUSDT|2018-07-25 05:00:00|  0.022|0.02206| 0.0213|0.02189|1.3751765E7|\n",
            "|VETUSDT|2018-07-25 05:15:00| 0.0219| 0.0219| 0.0212|0.02139|  6160434.0|\n",
            "|VETUSDT|2018-07-25 05:30:00|0.02139|0.02189|0.02135|0.02177|  7470119.0|\n",
            "|VETUSDT|2018-07-25 05:45:00|0.02178|0.02225|0.02178|0.02218|  8955663.0|\n",
            "|VETUSDT|2018-07-25 06:00:00|0.02219|0.02229|0.02159|0.02159|1.2489702E7|\n",
            "|VETUSDT|2018-07-25 06:15:00|0.02159|0.02167| 0.0215|0.02164|  5894843.0|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Query number 2: Filter with a Single Condition on Date\n"
      ],
      "metadata": {
        "id": "VGda9zeYhcqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Filter where datetime is after 2022-01-01\n",
        "result_df.filter(col(\"datetime\") > \"2022-01-01\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCkX7PmShpgD",
        "outputId": "728b3ae1-3daa-4f12-9a2d-67b1dd7b06b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+--------+--------+---------+\n",
            "|  pair|           datetime|    open|    high|     low|   close|   volume|\n",
            "+------+-------------------+--------+--------+--------+--------+---------+\n",
            "|ETHBTC|2022-01-01 00:00:00|0.079544|0.079757|0.079541|0.079672|1307.2555|\n",
            "|ETHBTC|2022-01-01 00:15:00|0.079672|0.079762|0.079667|0.079737| 396.1373|\n",
            "|ETHBTC|2022-01-01 00:30:00|0.079736|0.079736|  0.0796|0.079696| 485.6153|\n",
            "|ETHBTC|2022-01-01 00:45:00|0.079695|0.079808|0.079682|0.079805| 603.3572|\n",
            "|ETHBTC|2022-01-01 01:00:00|0.079805|0.079805| 0.07969|0.079714| 601.3664|\n",
            "|ETHBTC|2022-01-01 01:15:00|0.079709|0.079866|0.079705|0.079837|1219.3774|\n",
            "|ETHBTC|2022-01-01 01:30:00|0.079837|0.079886|0.079754|0.079834| 663.1523|\n",
            "|ETHBTC|2022-01-01 01:45:00|0.079833|0.079841| 0.07957|0.079637| 517.7116|\n",
            "|ETHBTC|2022-01-01 02:00:00|0.079628|0.079673|0.079527|0.079538|  478.672|\n",
            "|ETHBTC|2022-01-01 02:15:00|0.079541|0.079677| 0.07954|0.079635| 482.1326|\n",
            "+------+-------------------+--------+--------+--------+--------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 3: Multiple Conditions — AND fucntion"
      ],
      "metadata": {
        "id": "YNXUorZHiNAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# High price greater than 50000 AND volume > 2,000,000\n",
        "result_df.filter((col(\"high\") > 50000) & (col(\"volume\") > 2000000)).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G88KSJd1ifl6",
        "outputId": "bb93debd-2fb3-429b-bde7-b350be370a05"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+----+----+---+-----+------+\n",
            "|pair|datetime|open|high|low|close|volume|\n",
            "+----+--------+----+----+---+-----+------+\n",
            "+----+--------+----+----+---+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 4: Multiple Conditions — OR"
      ],
      "metadata": {
        "id": "pU0UIoX4kb4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open price OR close price is less than 100\n",
        "result_df.filter((col(\"open\") < 100) | (col(\"close\") < 100)).show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjgyS-JSkemJ",
        "outputId": "a481373d-d757-4bd0-d2c8-704f5b19ad96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "|  pair|           datetime|    open|    high|     low|   close| volume|\n",
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "|ETHBTC|2017-07-14 04:00:00|    0.08|  0.0864|    0.08|  0.0864|  8.752|\n",
            "|ETHBTC|2017-07-14 04:15:00|0.085289|   0.086|0.085128|0.085811| 61.042|\n",
            "|ETHBTC|2017-07-14 04:30:00|0.085811| 0.08638|0.085811|0.086314| 53.769|\n",
            "|ETHBTC|2017-07-14 04:45:00|0.086314| 0.08638|0.086309|0.086347| 42.818|\n",
            "|ETHBTC|2017-07-14 05:00:00|0.085874|0.086205|0.084608| 0.08468|  16.52|\n",
            "|ETHBTC|2017-07-14 05:15:00|0.084581|0.086196|0.084581| 0.08585| 22.144|\n",
            "|ETHBTC|2017-07-14 05:30:00| 0.08585|   0.086|0.085367|0.085669| 42.024|\n",
            "|ETHBTC|2017-07-14 05:45:00|0.085669|0.085957|0.085341|0.085399| 33.304|\n",
            "|ETHBTC|2017-07-14 06:00:00|0.085399|0.087001|0.085398|0.086973|162.135|\n",
            "|ETHBTC|2017-07-14 06:15:00|0.087097|0.087097|0.086883|0.086883| 35.316|\n",
            "+------+-------------------+--------+--------+--------+--------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Query number 5: Combined AND + OR"
      ],
      "metadata": {
        "id": "PwR2N5bekl5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open < 100 AND (volume > 1 million OR high > 90000)\n",
        "result_df.filter((col(\"open\") < 100) & ((col(\"volume\") > 1000000) | (col(\"high\") > 90000))).show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq-lbNhSkqid",
        "outputId": "9b74a45f-53ee-4280-dec7-ed292d4b4739"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+-------+-------+-------+-------+-----------+\n",
            "|   pair|           datetime|   open|   high|    low|  close|     volume|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+\n",
            "|VETUSDT|2018-07-25 04:00:00| 0.0225|0.02489| 0.0203|0.02106|3.7407276E7|\n",
            "|VETUSDT|2018-07-25 04:15:00|0.02152|0.02269|0.02147|0.02226|3.4112624E7|\n",
            "|VETUSDT|2018-07-25 04:30:00|0.02235| 0.0225|0.02165|0.02246|2.8341142E7|\n",
            "|VETUSDT|2018-07-25 04:45:00|0.02236| 0.0224|  0.022|  0.022| 1.129151E7|\n",
            "|VETUSDT|2018-07-25 05:00:00|  0.022|0.02206| 0.0213|0.02189|1.3751765E7|\n",
            "|VETUSDT|2018-07-25 05:15:00| 0.0219| 0.0219| 0.0212|0.02139|  6160434.0|\n",
            "|VETUSDT|2018-07-25 05:30:00|0.02139|0.02189|0.02135|0.02177|  7470119.0|\n",
            "|VETUSDT|2018-07-25 05:45:00|0.02178|0.02225|0.02178|0.02218|  8955663.0|\n",
            "|VETUSDT|2018-07-25 06:00:00|0.02219|0.02229|0.02159|0.02159|1.2489702E7|\n",
            "|VETUSDT|2018-07-25 06:15:00|0.02159|0.02167| 0.0215|0.02164|  5894843.0|\n",
            "+-------+-------------------+-------+-------+-------+-------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task B\n",
        "creating a new column called price_range, which shows the difference between the high and low prices for each row — a very common metric in financial/crypto data analysis."
      ],
      "metadata": {
        "id": "7-ns7u6klI8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create a new column called 'price_range' = high - low\n",
        "result_df = result_df.withColumn(\"price_range\", col(\"high\") - col(\"low\"))\n",
        "\n",
        "# Show a few rows to confirm the new column is added correctly\n",
        "result_df.select(\"pair\", \"datetime\", \"high\", \"low\", \"price_range\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlAEyfYGlPHk",
        "outputId": "89eb4f2b-c630-42ff-e05d-359e8fad2bd2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+--------+--------+------------+\n",
            "|  pair|           datetime|    high|     low| price_range|\n",
            "+------+-------------------+--------+--------+------------+\n",
            "|ETHBTC|2017-07-14 04:00:00|  0.0864|    0.08| 0.006400004|\n",
            "|ETHBTC|2017-07-14 04:15:00|   0.086|0.085128|8.7200105E-4|\n",
            "|ETHBTC|2017-07-14 04:30:00| 0.08638|0.085811|5.6900084E-4|\n",
            "|ETHBTC|2017-07-14 04:45:00| 0.08638|0.086309| 7.099658E-5|\n",
            "|ETHBTC|2017-07-14 05:00:00|0.086205|0.084608|0.0015969947|\n",
            "|ETHBTC|2017-07-14 05:15:00|0.086196|0.084581|0.0016149953|\n",
            "|ETHBTC|2017-07-14 05:30:00|   0.086|0.085367| 6.330013E-4|\n",
            "|ETHBTC|2017-07-14 05:45:00|0.085957|0.085341| 6.159991E-4|\n",
            "|ETHBTC|2017-07-14 06:00:00|0.087001|0.085398|0.0016029999|\n",
            "|ETHBTC|2017-07-14 06:15:00|0.087097|0.086883|2.1399558E-4|\n",
            "+------+-------------------+--------+--------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "withColumn(\"price_range\",) creates a new column.\n",
        "\n",
        "col(\"high\") - col(\"low\") subtracts values row-by-row.\n",
        "\n",
        "This helps visualize how volatile a crypto pair was during that period."
      ],
      "metadata": {
        "id": "CAaOZZvulihy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task C: Perform Aggregate Functions in PySpark\n",
        "We’ll run at least two aggregation queries using:\n",
        "\n",
        "avg() for average close price\n",
        "max() for maximum volume"
      ],
      "metadata": {
        "id": "VpoTrML0mE7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, max, min, sum"
      ],
      "metadata": {
        "id": "1lV6z6n9mKOD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Query number 1 — Average Close Price for All Pairs"
      ],
      "metadata": {
        "id": "Y-IhfIZsm8G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average close price\n",
        "avg_close = result_df.agg(avg(\"close\").alias(\"avg_close_price\"))\n",
        "avg_close.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwCxfzn0m99h",
        "outputId": "f860f75b-dafe-4c2a-86f8-fce0a42e21d6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|   avg_close_price|\n",
            "+------------------+\n",
            "|315.30973962842415|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 2 — Mininmum open price of the entire data set means all the pairs"
      ],
      "metadata": {
        "id": "arW4QdjKoTfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.agg(min(\"open\").alias(\"min_open_price\")).show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UWvDr5aoXJ9",
        "outputId": "b18a7b30-1feb-40fb-a1f8-b35cf7d55169"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|min_open_price|\n",
            "+--------------+\n",
            "|       6.95E-5|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task D\n",
        "Group by pair and calculate average close price"
      ],
      "metadata": {
        "id": "c2i5RA5hqeNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# Group by trading pair and calculate average close price\n",
        "avg_close_per_pair = result_df.groupBy(\"pair\") \\\n",
        "    .agg(avg(\"close\").alias(\"avg_close_price\"))\n",
        "\n",
        "# Show the result\n",
        "avg_close_per_pair.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBCGMwtLqjyl",
        "outputId": "8914a064-9c57-4d0a-841a-e517ebbc6ab0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|pair    |avg_close_price     |\n",
            "+--------+--------------------+\n",
            "|VETUSDT |0.033351619857801926|\n",
            "|TRXUSDT |0.05289777105559504 |\n",
            "|BTCUSDT |21807.118113527038  |\n",
            "|BNBUSDT |172.21060789427383  |\n",
            "|ADAUSDT |0.48033505673984955 |\n",
            "|ETHUSDT |1251.8066989186987  |\n",
            "|ETHBTC  |0.05157799774743873 |\n",
            "|XLMUSDT |0.16146420606724426 |\n",
            "|LTCUSDT |96.91862814289583   |\n",
            "|IOTAUSDT|0.4964321518321508  |\n",
            "+--------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "explanation\n",
        "groupBy(\"pair\"): groups all rows by the pair value\n",
        "\n",
        ".agg(avg(\"close\")): calculates the average closing price for each group\n",
        "\n",
        ".alias(...): renames the resulting column for clarity\n",
        "\n"
      ],
      "metadata": {
        "id": "bByJDa0bsVit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task E: Top 10 Highest Volume Trades Across All Pairs"
      ],
      "metadata": {
        "id": "3XhNUalesZMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the DataFrame by volume in descending order\n",
        "sorted_volume_df = result_df.orderBy(result_df[\"volume\"].desc())\n",
        "\n",
        "# Show the top 10 highest volume records\n",
        "sorted_volume_df.select(\"pair\", \"datetime\", \"volume\").show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YX59zxdsulT",
        "outputId": "311ca702-8a3d-476f-ed85-cbf405df1adf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+-------------+\n",
            "|pair        |datetime           |volume       |\n",
            "+------------+-------------------+-------------+\n",
            "|1000SATSUSDT|2023-12-12 12:00:00|1.24054217E11|\n",
            "|1000SATSUSDT|2023-12-12 12:15:00|4.2619228E10 |\n",
            "|1000SATSUSDT|2023-12-12 12:30:00|4.2222641E10 |\n",
            "|1000SATSUSDT|2023-12-14 16:00:00|3.5824419E10 |\n",
            "|1000SATSUSDT|2023-12-18 09:15:00|3.32747162E10|\n",
            "|1000SATSUSDT|2023-12-14 01:00:00|3.27737324E10|\n",
            "|1000SATSUSDT|2023-12-15 07:15:00|3.26273085E10|\n",
            "|1000SATSUSDT|2023-12-15 12:15:00|3.16866376E10|\n",
            "|1000SATSUSDT|2024-01-03 12:00:00|3.03175864E10|\n",
            "|1000SATSUSDT|2024-03-12 01:00:00|2.90051011E10|\n",
            "+------------+-------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "orderBy(...desc()): sorts from highest to lowest\n",
        "\n",
        "This helps find which coins had the most trading activity during a specific time"
      ],
      "metadata": {
        "id": "Mocvi3E-uc0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task F: We'll create a Left Join between:\n",
        "\n",
        "Your existing DataFrame result_df\n",
        "A second DataFrame containing the average volume per pair"
      ],
      "metadata": {
        "id": "iJr4Vn2HukZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Create a DataFrame with Average Volume Per Pair\n",
        " from pyspark.sql.functions import avg\n",
        "\n",
        "avg_volume_df = result_df.groupBy(\"pair\") \\\n",
        "    .agg(avg(\"volume\").alias(\"avg_volume\"))"
      ],
      "metadata": {
        "id": "Fwg6Vs2qvATn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performimng a Left Join on pair"
      ],
      "metadata": {
        "id": "_gi9KbCcvL4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df = result_df.join(avg_volume_df, on=\"pair\", how=\"left\")\n",
        "\n",
        "# Show sample result\n",
        "joined_df.select(\"pair\", \"datetime\", \"volume\", \"avg_volume\").show(10, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WphQ5BfvRP7",
        "outputId": "78f97209-3212-44d4-c57b-ec546aed37e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------------+-------+------------------+\n",
            "|pair  |datetime           |volume |avg_volume        |\n",
            "+------+-------------------+-------+------------------+\n",
            "|ETHBTC|2017-07-14 04:00:00|8.752  |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 04:15:00|61.042 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 04:30:00|53.769 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 04:45:00|42.818 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:00:00|16.52  |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:15:00|22.144 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:30:00|42.024 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 05:45:00|33.304 |1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 06:00:00|162.135|1674.6737597779027|\n",
            "|ETHBTC|2017-07-14 06:15:00|35.316 |1674.6737597779027|\n",
            "+------+-------------------+-------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "result_df contains individual trades\n",
        "\n",
        "avg_volume_df provides summary per pair\n",
        "The Left Join adds a new column avg_volume to each record, letting you compare individual volume vs average volume"
      ],
      "metadata": {
        "id": "CLn-l3xuwNFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task G Window Functions[link text](https://)\n",
        "Import Required Modules"
      ],
      "metadata": {
        "id": "ZZIvqQ29wY5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, dense_rank, lag, lead\n"
      ],
      "metadata": {
        "id": "xDLWLFvjymCh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 1: Add rank() by pair based on volume (most volume = rank 1)"
      ],
      "metadata": {
        "id": "K6oWw0OdzIxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define window: partition by pair, order by volume descending\n",
        "window_spec_rank = Window.partitionBy(\"pair\").orderBy(result_df[\"volume\"].desc())\n",
        "\n",
        "# Apply rank\n",
        "ranked_df = result_df.withColumn(\"volume_rank\", rank().over(window_spec_rank))\n",
        "\n",
        "# Show ranked results\n",
        "ranked_df.select(\"pair\", \"datetime\", \"volume\", \"volume_rank\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcV2R604zMbd",
        "outputId": "fc2d3e95-24ad-46eb-a3b0-f42ade388bb5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-----------+-----------+\n",
            "|    pair|           datetime|     volume|volume_rank|\n",
            "+--------+-------------------+-----------+-----------+\n",
            "|AGIXUSDT|2023-03-03 01:30:00|2.5388476E7|          1|\n",
            "|AGIXUSDT|2024-02-16 09:30:00| 1.873388E7|          2|\n",
            "|AGIXUSDT|2023-03-14 17:00:00|1.8614436E7|          3|\n",
            "|AGIXUSDT|2023-05-25 16:00:00|1.8072368E7|          4|\n",
            "|AGIXUSDT|2023-03-14 18:45:00|1.7988518E7|          5|\n",
            "|AGIXUSDT|2023-06-22 10:00:00|1.6398441E7|          6|\n",
            "|AGIXUSDT|2023-02-28 04:00:00|  1.61187E7|          7|\n",
            "|AGIXUSDT|2023-03-14 19:15:00| 1.561941E7|          8|\n",
            "|AGIXUSDT|2023-03-22 18:00:00|1.5500232E7|          9|\n",
            "|AGIXUSDT|2024-02-21 22:45:00|1.5429726E7|         10|\n",
            "+--------+-------------------+-----------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number 2: Use lag() to compare close price to previous row (per pair)"
      ],
      "metadata": {
        "id": "Ed84xq9lz1Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define window: partition by pair, order by datetime\n",
        "window_spec_lag = Window.partitionBy(\"pair\").orderBy(\"datetime\")\n",
        "\n",
        "# Add lag column (previous row's close)\n",
        "lag_df = result_df.withColumn(\"previous_close\", lag(\"close\", 1).over(window_spec_lag))\n",
        "\n",
        "# Show result with previous close comparison\n",
        "lag_df.select(\"pair\", \"datetime\", \"close\", \"previous_close\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4cR8mzDz5-D",
        "outputId": "55779a49-bc5e-4f83-8bf9-e82ae3a4ed48"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-------+--------------+\n",
            "|    pair|           datetime|  close|previous_close|\n",
            "+--------+-------------------+-------+--------------+\n",
            "|AGIXUSDT|2023-02-17 08:00:00|0.43829|          NULL|\n",
            "|AGIXUSDT|2023-02-17 08:15:00|0.42992|       0.43829|\n",
            "|AGIXUSDT|2023-02-17 08:30:00|0.43236|       0.42992|\n",
            "|AGIXUSDT|2023-02-17 08:45:00|0.43561|       0.43236|\n",
            "|AGIXUSDT|2023-02-17 09:00:00|0.43194|       0.43561|\n",
            "|AGIXUSDT|2023-02-17 09:15:00|0.43121|       0.43194|\n",
            "|AGIXUSDT|2023-02-17 09:30:00|0.43136|       0.43121|\n",
            "|AGIXUSDT|2023-02-17 09:45:00|0.43351|       0.43136|\n",
            "|AGIXUSDT|2023-02-17 10:00:00|0.43262|       0.43351|\n",
            "|AGIXUSDT|2023-02-17 10:15:00| 0.4336|       0.43262|\n",
            "+--------+-------------------+-------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: rank(): assigns volume-based rank within each pair\n",
        "\n",
        "lag(): brings in previous row’s close price for comparison"
      ],
      "metadata": {
        "id": "xp7JBRZ-z_YW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task H: Aggregate Window Functions\n",
        "These combine aggregates (like avg, sum) with windowing, allowing you to calculate running totals, moving averages, and group-based aggregates without collapsing rows (unlike groupBy())."
      ],
      "metadata": {
        "id": "pVPQqjT70bXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg, sum\n",
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "ic9EAl_40c0f"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query number  1: Moving Average of Close Price (Per Pair Ordered by Date)"
      ],
      "metadata": {
        "id": "z1zKH7XO1afX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a rolling window: current row and 2 previous rows, ordered by datetime\n",
        "window_spec_avg = Window.partitionBy(\"pair\").orderBy(\"datetime\").rowsBetween(-2, 0)\n",
        "\n",
        "# Add 3-row moving average column\n",
        "moving_avg_df = result_df.withColumn(\"moving_avg_close\", avg(\"close\").over(window_spec_avg))\n",
        "\n",
        "# Show result\n",
        "moving_avg_df.select(\"pair\", \"datetime\", \"close\", \"moving_avg_close\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4PkivCF1cPs",
        "outputId": "50a7c735-7266-4d1e-eb71-c468d43fa865"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+-------+-------------------+\n",
            "|    pair|           datetime|  close|   moving_avg_close|\n",
            "+--------+-------------------+-------+-------------------+\n",
            "|AGIXUSDT|2023-02-17 08:00:00|0.43829|  0.438289999961853|\n",
            "|AGIXUSDT|2023-02-17 08:15:00|0.42992| 0.4341049939393997|\n",
            "|AGIXUSDT|2023-02-17 08:30:00|0.43236| 0.4335233271121979|\n",
            "|AGIXUSDT|2023-02-17 08:45:00|0.43561|0.43262999256451923|\n",
            "|AGIXUSDT|2023-02-17 09:00:00|0.43194| 0.4333033263683319|\n",
            "|AGIXUSDT|2023-02-17 09:15:00|0.43121| 0.4329199989636739|\n",
            "|AGIXUSDT|2023-02-17 09:30:00|0.43136|0.43150333563486737|\n",
            "|AGIXUSDT|2023-02-17 09:45:00|0.43351| 0.4320266743501027|\n",
            "|AGIXUSDT|2023-02-17 10:00:00|0.43262|0.43249666690826416|\n",
            "|AGIXUSDT|2023-02-17 10:15:00| 0.4336| 0.4332433342933655|\n",
            "+--------+-------------------+-------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Query number 2: Running Total of Volume (Cumulative Sum per Pair)"
      ],
      "metadata": {
        "id": "tvX5FYhE3L1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define cumulative window ordered by datetime per pair\n",
        "window_spec_sum = Window.partitionBy(\"pair\").orderBy(\"datetime\").rowsBetween(Window.unboundedPreceding, 0)\n",
        "\n",
        "# Add cumulative volume column\n",
        "running_total_df = result_df.withColumn(\"cumulative_volume\", sum(\"volume\").over(window_spec_sum))\n",
        "\n",
        "# Show result\n",
        "running_total_df.select(\"pair\", \"datetime\", \"volume\", \"cumulative_volume\").show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqKCZ-5l3ODz",
        "outputId": "9fd99ab1-ba79-4372-b4e1-7a00524de636"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------------+---------+-----------------+\n",
            "|    pair|           datetime|   volume|cumulative_volume|\n",
            "+--------+-------------------+---------+-----------------+\n",
            "|AGIXUSDT|2023-02-17 08:00:00|3256768.0|        3256768.0|\n",
            "|AGIXUSDT|2023-02-17 08:15:00|1236058.0|        4492826.0|\n",
            "|AGIXUSDT|2023-02-17 08:30:00| 840131.0|        5332957.0|\n",
            "|AGIXUSDT|2023-02-17 08:45:00| 377821.0|        5710778.0|\n",
            "|AGIXUSDT|2023-02-17 09:00:00| 672372.0|        6383150.0|\n",
            "|AGIXUSDT|2023-02-17 09:15:00| 200868.0|        6584018.0|\n",
            "|AGIXUSDT|2023-02-17 09:30:00| 395115.0|        6979133.0|\n",
            "|AGIXUSDT|2023-02-17 09:45:00| 434877.0|        7414010.0|\n",
            "|AGIXUSDT|2023-02-17 10:00:00| 437388.0|        7851398.0|\n",
            "|AGIXUSDT|2023-02-17 10:15:00| 665352.0|        8516750.0|\n",
            "+--------+-------------------+---------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "rowsBetween(-2, 0) = current row and 2 previous → perfect for moving average\n",
        "\n",
        "Window.unboundedPreceding = start from beginning → perfect for running totals\n",
        "The result keeps row granularity, unlike groupBy()"
      ],
      "metadata": {
        "id": "F79q25If3bSx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}